{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Regression on House Pricing Dataset: Variable Selection & Regularization\n",
    "We consider a reduced version of a dataset containing house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
    "\n",
    "[https://www.kaggle.com/harlfoxem/housesalesprediction]\n",
    "\n",
    "For each house we know 18 house features (e.g., number of bedrooms, number of bathrooms, etc.) plus its price, that is what we would like to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1: insert your ID number (\"numero di matricola\") below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put here your ``numero di matricola''\n",
    "numero_di_matricola = # COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all packages needed\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, remove data samples/points with missing values (NaN) and take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "df = pd.read_csv('kc_house_data.csv', sep = ',')\n",
    "\n",
    "#remove the data samples with missing values (NaN)\n",
    "df = df.dropna() \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract input and output data. We want to predict the price by using features other than id as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = df.values\n",
    "# m = number of input samples\n",
    "m = 3164\n",
    "Y = Data[:m,2]\n",
    "X = Data[:m,3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Split the data into training  set of $m_{train}=50$ samples and a test set of $m_{test}:=m-m_{train}$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train (50 samples) and test data (the rest)\n",
    "m_train = 50\n",
    "\n",
    "m_test = m - m_train \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=m_test/m, random_state=numero_di_matricola)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "Xtrain_scaled = scaler.transform(Xtrain)\n",
    "Xtest_scaled = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Squared Loss Solution\n",
    "\n",
    "Now compute the solution for linear regression with squared loss (i.e., the Least-Squares estimate) using LinearRegression() in Scikit-learn, and print the corresponding average loss in training and test data.\n",
    "\n",
    "Since the average loss can be quite high, we also compute the coefficient of determination $R^2$ and look at $1 - R^{2}$ to have an idea of what the average loss amounts to. To compute the coefficient of determination you can use the \"score(...)\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least-Squares\n",
    "from sklearn import linear_model \n",
    "#LR the linear regression model\n",
    "LR = linear_model.LinearRegression()\n",
    "\n",
    "#fit the model on training data\n",
    "LR.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#obtain predictions on training data\n",
    "Ytrain_predicted = LR.predict(Xtrain_scaled)\n",
    "\n",
    "#obtain predictions on test data\n",
    "Ytest_predicted = LR.predict(Xtest_scaled)\n",
    "\n",
    "#coefficients from the model\n",
    "w_LR = np.hstack((LR.intercept_, LR.coef_))\n",
    "\n",
    "#average error in training data\n",
    "loss_train = np.linalg.norm(Ytrain - Ytrain_predicted)**2/m_train\n",
    "\n",
    "#average error in test data\n",
    "loss_test =np.linalg.norm(Ytest - Ytest_predicted)**2/m_test\n",
    "\n",
    "#print average loss in training data and in test data\n",
    "print(\"Average loss in training data:\"+str(loss_train))\n",
    "print(\"Average loss in test data:\"+str(loss_test))\n",
    "\n",
    "#print 1 - coefficient of determination in training data and in test data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - LR.score(Xtrain_scaled,Ytrain)))\n",
    "print(\"1 - coefficient of determination on test data:\"+str(1 - LR.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals\n",
    "\n",
    "We now compute the confidence interval for each coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least-Squares: Confidence Intervals\n",
    "from scipy.stats import t\n",
    "\n",
    "Xtrain_im_testrcept = np.hstack((np.ones((Xtrain_scaled.shape[0],1)), Xtrain_scaled))\n",
    "\n",
    "#alpha for confidence intervals\n",
    "alpha = 0.05\n",
    "\n",
    "d = Xtrain_scaled.shape[1]-1\n",
    "\n",
    "#quantile from t-student distribution\n",
    "tperc = t.ppf(1-alpha/2, m_train-d-1, loc=0, scale=1)\n",
    "sigma2 = np.linalg.norm(Ytrain-Ytrain_predicted)**2/(m_train-d-1)\n",
    "\n",
    "R = np.dot(Xtrain_im_testrcept.transpose(),Xtrain_im_testrcept)\n",
    "Ur, Sr, Vr = np.linalg.svd(R, full_matrices=1, compute_uv=1)\n",
    "\n",
    "\n",
    "Sri = 1/Sr\n",
    "Sri = Sri*(Sri<1e10)\n",
    "\n",
    "Ri2 = np.dot(Ur,np.dot(np.diag(Sri),np.transpose(Ur)))\n",
    "\n",
    "v = np.sqrt(np.diag(Ri2))\n",
    "Delta = np.sqrt(sigma2)*v*tperc\n",
    "CI = np.transpose(np.vstack((w_LR,w_LR))) + np.transpose(np.vstack((-Delta,+Delta) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the LS coefficients and their confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confidence\n",
    "plt.figure(1)\n",
    "plt.plot(w_LR[1:], 'r', marker='o', ms=7.0)\n",
    "plt.plot(CI[1:,0], 'b--')\n",
    "plt.plot(CI[1:,1], 'b--')\n",
    "plt.plot(np.zeros(w_LR.shape[0],), 'k', linewidth=2.0)\n",
    "plt.xlabel('Coefficient Index')\n",
    "plt.ylabel('LR Coefficient')\n",
    "plt.title('Coefficients and Confidence Sets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: based on the results above, if you had to choose at most 4 features for a linear regression model, which ones would you choose? Why?\n",
    "\n",
    "### TO DO 2\n",
    "Answer the question above (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best-Subset Selection\n",
    "\n",
    "Split the (previous) training data (i.e., the 50 samples chosen above) into a training data and validation dataset to perform best-subset selection. For splitting, put 50% of the data into the validation set.\n",
    "\n",
    "For $k$ going from 1 to $n_{sub}=4$:\n",
    "1. Compute the best model for all the possible subsets of $k$ features\n",
    "2. Compute the prediction error on the validation dataset\n",
    "\n",
    "Finally we choose the subset of $k^*$ features giving the lowest validation error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math \n",
    "\n",
    "m_trainBSS=int(math.ceil(m_train/2))\n",
    "m_valBSS=m_train-m_trainBSS\n",
    "\n",
    "\n",
    "Xtrain_BSS = Xtrain_scaled[:m_trainBSS,:]\n",
    "Ytrain_BSS = Ytrain[:m_trainBSS]\n",
    "Xval_BSS = Xtrain_scaled[m_trainBSS:,:]\n",
    "Yval_BSS = Ytrain[m_trainBSS:,]\n",
    "\n",
    "nsub = 4\n",
    "features_idx_dict = {}\n",
    "validation_err_dict = {}\n",
    "validation_err_min = np.zeros(nsub,)\n",
    "validation_err_min_idx = np.zeros(nsub, dtype=np.int64)\n",
    "for k in range(1,nsub+1):\n",
    "    features_idx = list(itertools.combinations(range(Xtrain_BSS.shape[1]),k))\n",
    "    validation_error = np.zeros(len(features_idx),)\n",
    "    for j in range(len(features_idx)):\n",
    "        LR_subset = linear_model.LinearRegression()\n",
    "        LR_subset.fit(Xtrain_BSS[:,features_idx[j]], Ytrain_BSS)\n",
    "        validation_error[j] = np.linalg.norm(Yval_BSS - LR_subset.predict(Xval_BSS[:,features_idx[j]]))**2/m_valBSS \n",
    "    validation_err_min[k-1] = np.min(validation_error)    \n",
    "    validation_err_min_idx[k-1] = np.argmin(validation_error)\n",
    "    features_idx_dict.update({k: features_idx})\n",
    "    validation_err_dict.update({k: validation_error})\n",
    "    \n",
    "print(\"Validation error as a function of k (starting at k=2): \"+str(validation_err_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the validation error as a function of the number of retained features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(2)\n",
    "for k in range(1,nsub+1):\n",
    "    plt.scatter(k*np.ones(validation_err_dict[k].shape), validation_err_dict[k], color='k', alpha=0.5)\n",
    "    #plt.scatter(k, validation_err_min[k-1], color='r', alpha=0.8)\n",
    "    if k > 1:\n",
    "        plt.plot([k-1, k], [validation_err_min[k-2], validation_err_min[k-1]], color='r',marker='o', \n",
    "            markeredgecolor='k', markerfacecolor = 'r', markersize = 10)\n",
    "plt.xlabel('Number of retained features')\n",
    "plt.ylabel('Avg. validation error')\n",
    "plt.title('Best-Subset Selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the model using the selected subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 3: pick the number of features for the best subset according to figure above, learn the model on the entire training data (i.e., the 50 samples chosen at the beginning), and compute score on training and on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_best_subset = linear_model.LinearRegression()\n",
    "\n",
    "# now pick the number of features according to best subset\n",
    "opt_num_features = # COMPLETE\n",
    "\n",
    "#opt_features_idx contains the indices of the features from best subset\n",
    "opt_features_idx = # COMPLETE\n",
    "\n",
    "#let's print the indices of the features from best subset\n",
    "print(opt_features_idx)\n",
    "\n",
    "#fit the best subset on the entire training set\n",
    "LR_best_subset.fit(Xtrain_scaled[:,opt_features_idx], Ytrain)\n",
    "\n",
    "#obtain predictions on training data\n",
    "Ytrain_predicted_best_subset = # COMPLETE\n",
    "\n",
    "#obtain predictions on test data\n",
    "Ytest_predicted_best_subset = # COMPLETE\n",
    "\n",
    "#average loss in training data\n",
    "loss_train_best_subset = # COMPLETE\n",
    "\n",
    "#average loss in test data\n",
    "loss_test_best_subset = # COMPLETE\n",
    "\n",
    "#print average loss in training data and in test data\n",
    "print(\"Average loss in training data:\"+str(loss_train_best_subset))\n",
    "print(\"Average loss in test data:\"+str(loss_test_best_subset))\n",
    "\n",
    "#now print 1-  the coefficient of determination on training and on test data to get an idea to what the average\n",
    "#loss corresponds to\n",
    "print(\"1 - coefficient of determination of best subset on training data: \"+str(1 - LR_best_subset.score(Xtrain_scaled[:,opt_features_idx],Ytrain)))\n",
    "print(\"1 - coefficient of determination of best subset on test data: \"+str(1 - LR_best_subset.score(Xtest_scaled[:,opt_features_idx],Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 4: do the features from best subset selection correspond to the ones you would have chosen based on confidence intervals for the linear regression coefficients? Comment (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso\n",
    "\n",
    "### TO DO 5\n",
    "Use the routine *lasso_path* from *sklearn.linear_regression* to compute the \"lasso path\" for different values of the regularization parameter $\\lambda$. You should first fix a grid a possible values of lambda (the variable \"lasso_lams\"). For each entry of the vector \"lasso_lams\" you should compute the corresponding model (The i-th column of the vector  \"lasso_coefs\" should contain the coefficients of the linear model computed using lasso_lams[i] as regularization parameter).\n",
    "\n",
    "Be careful that the grid should be chosen appropriately.\n",
    "\n",
    "Note that the parameter $\\lambda$ is called $\\alpha$ in the Lasso model from sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lasso_path\n",
    "\n",
    "# select a grid of possible regularization parameters \n",
    "# (be carefull how this is chosen, you may have to refine the choice after having seen the results)\n",
    "\n",
    "#Note: lasso_lams is supposed to be a numpy array\n",
    "lasso_lams = # COMPLETE\n",
    "\n",
    "# Use the function lasso_path to compute the \"lasso path\", passing in input the lambda values\n",
    "# you have specified in lasso_lams\n",
    "lasso_lams, lasso_coefs, _ = # COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the sparsity in the estimated coefficients as a function of the regularization parameter $\\lambda$: to this purpose, compute the number of non-zero entries in the estimated coefficient vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0_coef_norm = np.zeros(len(lasso_lams),)\n",
    "\n",
    "for i in range(len(lasso_lams)):\n",
    "    l0_coef_norm[i] = sum(lasso_coefs[:,i]!=0)\n",
    "\n",
    "\n",
    "plt.figure(6)\n",
    "plt.plot(lasso_lams, l0_coef_norm, marker='o', markersize=5)\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Number of non-zero coefficients')\n",
    "plt.title('Sparsity Degree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 6: explain the results you observe in the figure above (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 7: Use k-fold Cross-Validation to fix the regularization parameter\n",
    "\n",
    "Use the scikit-learn built-in routine *Lasso* (from the *linear_regression* package) to compute the lasso  coefficients.\n",
    "\n",
    "Use *KFold* from *sklearn.cross_validation* to split the data (i.e. Xtrain_scaled and Ytrain) into the desired number of folds.\n",
    "\n",
    "Then pick $lam\\_opt$ to be the chosen value for the regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_folds = 5\n",
    "\n",
    "kf = KFold(n_splits = num_folds)\n",
    "\n",
    "#loss_lasso_kfold will contain the value of the loss\n",
    "loss_lasso_kfold = np.zeros(len(lasso_lams),)\n",
    "\n",
    "for i in range(len(lasso_lams)):\n",
    "    \n",
    "    #define a lasso model   using Lasso() for the i-th value of lam_values\n",
    "    lasso_kfold = # COMPLETE\n",
    "    for train_index, validation_index in kf.split(Xtrain_scaled):\n",
    "        Xtrain_kfold, Xval_kfold = Xtrain_scaled[train_index], Xtrain_scaled[validation_index]\n",
    "        Ytrain_kfold, Yval_kfold = Ytrain[train_index], Ytrain[validation_index]\n",
    "    \n",
    "        #learn the model using the training data from the k-fold\n",
    "        \n",
    "        # ADD CODE\n",
    "        \n",
    "        #compute the loss using the validation data from the k-fold\n",
    "\n",
    "        # ADD CODE\n",
    "    \n",
    "# loss_lass_kfold should be the average loss observed in the folds\n",
    "loss_lasso_kfold /= num_folds\n",
    "\n",
    "\n",
    "#choose the regularization parameter that minimizes the loss\n",
    "lasso_lam_opt = # COMPLETE\n",
    "print(\"Best value of the regularization parameter:\", lasso_lam_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Cross-Validation estimate of the prediction error as a function of the regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(4)\n",
    "plt.xscale('log')\n",
    "plt.plot(lasso_lams, loss_lasso_kfold, color='b')\n",
    "plt.scatter(lasso_lams[np.argmin(loss_lasso_kfold)], loss_lasso_kfold[np.argmin(loss_lasso_kfold)], color='b', marker='o', linewidths=5)\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Validation Error')\n",
    "plt.title('Lasso: choice of regularization parameter')\n",
    "plt.show()\n",
    "print(\"Total number of coefficients:\"+str(len(lasso_kfold.coef_)))\n",
    "print(\"Number of non-zero coefficients:\"+str(sum(lasso_kfold.coef_ != 0)))\n",
    "print(\"Best value of regularization parameter:\"+str(lasso_lam_opt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 8 now estimate the lasso coefficients using all the training data and the optimal regularization parameter (chosen at previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Lasso  Coefficients with all data (trainval) for the the optimal value lasso_lam_opt of the regularization paramter\n",
    "\n",
    "#define the model\n",
    "lasso_reg = # COMPLETE\n",
    "\n",
    "#fit using the training data\n",
    "\n",
    "# ADD CODE\n",
    "\n",
    "#average loss on training data\n",
    "loss_train_lasso = # COMPLETE\n",
    "#average loss on test data\n",
    "loss_test_lasso = # COMPLETE\n",
    "\n",
    "#print average loss in training data and in test data\n",
    "print(\"Average loss in training data:\"+str(loss_train_lasso))\n",
    "print(\"Average loss in test data:\"+str(loss_test_lasso))\n",
    "\n",
    "#now print 1-  the coefficient of determination on training and on test data to get an idea to what the average\n",
    "#loss corresponds to\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - lasso_reg.score(Xtrain_scaled,Ytrain)))\n",
    "print(\"1 - coefficient of determination on test data:\"+str(1 - lasso_reg.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the LR and the Lasso coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LR and lasso coefficients\n",
    "ind = np.arange(1,len(LR.coef_)+1)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, LR.coef_, width, color='r')\n",
    "rects2 = ax.bar(ind + width, lasso_reg.coef_, width, color='y')\n",
    "ax.legend((rects1[0], rects2[0]), ('LR', 'Lasso'))\n",
    "plt.xlabel('Coefficient Idx')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('LR and Lasso Coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "## TO DO 9\n",
    "### Use Ridge regression with cross-validation\n",
    "\n",
    "We perform Ridge regression (i.e., linear regression with squared loss and L2 regularization) for different values of the regularization parameter $\\alpha$ (called $\\lambda$ in class), and use the Scikit-learn function to perform cross-validation (CV).\n",
    "\n",
    "In Ridge regression for scikit learn, the objective function is:\n",
    "\n",
    "$$\n",
    "    ||y - Xw||^2_2 + \\alpha * ||w||^2_2\n",
    "$$\n",
    "\n",
    "In the code below:\n",
    "- use RidgeCV() to select the best value of $\\alpha$ with a 5-fold CV with L2 penalty;\n",
    "- use Ridge() to learn the best model for the best $\\alpha$ for ridge regression using the entire training set (i.e., the 50 samples chosen at the beginning)\n",
    "\n",
    "Note that RidgeCV() picks some default values of $\\alpha$ to try, but we decide to pass the same values used for the Lasso.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's define the values of alpha to use\n",
    "ridge_alphas = # COMPLETE\n",
    "\n",
    "#define the model using RidgeCV passing the vector of alpha values and the cv value (= number of folds)\n",
    "ridge = # COMPLETE\n",
    "\n",
    "#fit the model on training data\n",
    "\n",
    "# ADD CODE\n",
    "\n",
    "# the attribute 'alpha_' contains the best value of alpha as identified by cross-validation;\n",
    "# let's print it\n",
    "\n",
    "print(\"Best value of parameter alpha according to 5-fold Cross-Validation: \"+str(ridge.alpha_))\n",
    "\n",
    "#define the model using the best alpha; note that various solvers are availalbe, choose\n",
    "# an appropriate one\n",
    "ridge_final = # COMPLETE\n",
    "\n",
    "#fit the model using the best C on the entire training set\n",
    "\n",
    "# ADD CODE\n",
    "\n",
    "#average loss on training data\n",
    "loss_train_ridge = # COMPLETE\n",
    "\n",
    "#average loss on test data\n",
    "loss_test_ridge = # COMPLETE\n",
    "\n",
    "#print average loss in training data and in test data\n",
    "print(\"Average loss in training data:\"+str(loss_train_ridge))\n",
    "print(\"Average loss in test data:\"+str(loss_test_ridge))\n",
    "\n",
    "#now print 1-  the coefficient of determination on training and on test data to get an idea to what the average\n",
    "#loss corresponds to\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - ridge_final.score(Xtrain_scaled,Ytrain)))\n",
    "print(\"1 - coefficient of determination on test data:\"+str(1 - ridge_final.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare LR, Lasso, and Ridge regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LR and lasso coefficients\n",
    "ind = np.arange(1,len(LR.coef_)+1)  # the x locations for the groups\n",
    "width = 0.25       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, LR.coef_, width, color='r')\n",
    "rects2 = ax.bar(ind + width, lasso_reg.coef_, width, color='y')\n",
    "rects3 = ax.bar(ind + 2*width, ridge_final.coef_, width, color='b')\n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('LR', 'Lasso', 'Ridge'))\n",
    "plt.xlabel('Coefficient Idx')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('LR, Lasso, and Ridge Coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 10: comment on the coefficients obtained by the different methods and their comparison (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Comparison of models: evaluation of the performance on the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average loss of LR on test data:\"+str(loss_test))\n",
    "print(\"Average loss of LR with subset selection on test data:\"+str(loss_test_best_subset))\n",
    "print(\"Average loss of LASSO on test data:\"+str(loss_test_lasso))\n",
    "print(\"Average loss of Ridge regression on test data:\"+str(loss_test_ridge))\n",
    "\n",
    "print(\"1 - coefficient of determination of LR on test data:\"+str(1 - LR.score(Xtest_scaled,Ytest)))\n",
    "print(\"1 - coefficient of determination of LR with best subset on test data: \"+str(1 - LR_best_subset.score(Xtest_scaled[:,opt_features_idx],Ytest)))\n",
    "print(\"1 - coefficient of determination of LASSO on test data:\"+str(1 - lasso_reg.score(Xtest_scaled,Ytest)))\n",
    "print(\"1 - coefficient of determination of Ridge regression on test data:\"+str(1 - ridge_final.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 11: comment and compare the results obtained by the different methods (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 12: using your final model of choice (write which one you choose), what are the features that seem more relevant for the prices of houses? Does this match your intuition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUGGESTION (not compulsory): repeat the entire analysis above using a different data size, and try to understand the differences that you observe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
